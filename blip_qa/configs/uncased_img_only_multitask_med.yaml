# data related
train_file: '/ocean/projects/cis210027p/shared/corpora/webqa/WebQA_train_val.json'
val_file: '/ocean/projects/cis210027p/shared/corpora/webqa/WebQA_train_val.json'
# test_file: '/ocean/projects/cis210027p/shared/corpora/webqa/WebQA_test.json'
test_file: 'test_img_only.json'
image_dir: '/ocean/projects/cis210027p/shared/corpora/webqa/images'

image_size: 480
image_only: true

# set pretrained as a file path or an url
pretrained: 'https://storage.googleapis.com/sfr-vision-language-research/BLIP/models/model_base_vqa_capfilt_large.pth'

# tokenizer
cased: false

# size of vit model; base or large
vit: 'base'
batch_size_train: 4
batch_size_val: 8
batch_size_test: 8
vit_grad_ckpt: False
vit_ckpt_layer: 0
init_lr: 1e-4

# optimizer
weight_decay: 0.05
min_lr: 0
max_epoch: 15
grad_accum: 8
grad_clip: 5

# multitask
multitask_qcate: true
alpha: 0.7

# med
med: true

# ablation study
no_img_input: false
